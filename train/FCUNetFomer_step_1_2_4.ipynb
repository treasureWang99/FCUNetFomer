{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.nn import init as init\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device2 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_step = 20\n",
    "num_window = 4\n",
    "num_predict_window = 4; ##step can 1、2、4\n",
    "img_n = 16\n",
    "img_h = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_plus(Dataset):\n",
    "    def __init__(self, label_dir):\n",
    "        self.label_dir = os.path.join(label_dir, \"S\")\n",
    "        self.refine_well_dir = os.path.join(label_dir, \"Well\")\n",
    "        self.K_dir = os.path.join(label_dir, \"K\")\n",
    "        self.Pore_dir = os.path.join(label_dir, \"Pore\")\n",
    "        self.Pressure_dir = os.path.join(label_dir, \"Pressure\")\n",
    "        \n",
    "\n",
    "        self.refine_file_list = os.listdir(self.refine_well_dir)\n",
    "        self.K_file_list = os.listdir(self.K_dir)\n",
    "        self.Pore_file_list = os.listdir(self.Pore_dir)\n",
    "        self.Pressure_file_list = os.listdir(self.Pressure_dir)\n",
    "        \n",
    "        self.label_file_list = os.listdir(self.label_dir )\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_file_list)* 4\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // 4\n",
    "        rotation_index = index % 4\n",
    "        refine_file_name = self.refine_file_list[file_index]\n",
    "        K_file_name = self.K_file_list[file_index]\n",
    "        \n",
    "        Pore_file_name = self.Pore_file_list[file_index]\n",
    "        Pressure_file_name = self.Pressure_file_list[file_index]\n",
    "        \n",
    "        label_file_name = self.label_file_list[file_index]\n",
    "        \n",
    "        refine_file_path = os.path.join(self.refine_well_dir, refine_file_name)\n",
    "        K_file_path = os.path.join(self.K_dir, K_file_name)\n",
    "        Pore_file_path = os.path.join(self.Pore_dir, Pore_file_name)\n",
    "        Pressure_file_path = os.path.join(self.Pressure_dir, Pressure_file_name)\n",
    "        \n",
    "        label_file_path = os.path.join(self.label_dir, label_file_name)\n",
    "        \n",
    "        K_data = scipy.io.loadmat(K_file_path)\n",
    "        K_array = (np.log(K_data['K']))\n",
    "        K_tensor = torch.from_numpy(K_array).reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        K_RError = torch.rot90(torch.from_numpy(scipy.io.loadmat(K_file_path)['K']).reshape(1,img_n,img_n,img_h).to(device2).float(), k=rotation_index, dims=(1, 2))\n",
    "        Pore_data = scipy.io.loadmat(Pore_file_path)\n",
    "        Pore_array = Pore_data['p']\n",
    "        Pore_tensor = torch.from_numpy(Pore_array).reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        Pore_RError = torch.rot90(Pore_tensor, k=rotation_index, dims=(1, 2))\n",
    "        Pressure_data = scipy.io.loadmat(Pressure_file_path)\n",
    "        Pressure_array = (Pressure_data['pressure'])\n",
    "        Pressure_tensor = torch.from_numpy(Pressure_array.transpose(3,0,1,2))[:num_step].to(device2).float()* 1e-7  / 2.\n",
    "        Pressure_tensor = torch.rot90(Pressure_tensor, k=rotation_index, dims=(1, 2))\n",
    "      \n",
    "        \n",
    "        label_data = scipy.io.loadmat(label_file_path)\n",
    "        \n",
    "        label_array = label_data['Ssmatrix']\n",
    "        \n",
    "        label_refine_well = torch.from_numpy(scipy.io.loadmat(refine_file_path)[\"wc_globale_refine\"]).to(device2).float()\n",
    "        \n",
    "        input_refine_well = label_refine_well.reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        \n",
    "        intermediate_condition = torch.cat([F.normalize(K_tensor,dim=0),F.normalize(Pore_tensor,dim=0),input_refine_well],axis=0)\n",
    "        intermediate_condition = torch.rot90(intermediate_condition, k=rotation_index, dims=(1, 2))\n",
    "        \n",
    "        label_tensor = torch.from_numpy(label_array.transpose(3,4,0,1,2))[:,:num_step].to(device2)\n",
    "        label_tensor = torch.rot90(label_tensor, k=rotation_index, dims=(2, 3))\n",
    "        return  (label_tensor).float(),(intermediate_condition).float(),Pressure_tensor.float(),K_RError,Pore_RError\n",
    "\n",
    "label_dir = ''  # your dataset\n",
    "dataset = CustomDataset_plus(label_dir)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "torch.save(train_dataset,'./pt/train_dataset.pt')\n",
    "torch.save(valid_dataset,'./pt/valid_dataset.pt')\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_weights(module_list, scale=1, bias_fill=0, **kwargs):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Args:\n",
    "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
    "        scale (float): Scale initialized weights, especially for residual\n",
    "            blocks. Default: 1.\n",
    "        bias_fill (float): The value to fill bias. Default: 0\n",
    "        kwargs (dict): Other arguments for initialization function.\n",
    "    \"\"\"\n",
    "    if not isinstance(module_list, list):\n",
    "        module_list = [module_list]\n",
    "    for module in module_list:\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_c,out_c,mid_c=None,residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        \n",
    "        if not mid_c:\n",
    "            mid_c = out_c\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_c,mid_c,kernel_size=3,padding=1),\n",
    "            nn.GroupNorm(1,mid_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_c,out_c,kernel_size=3,padding=1),\n",
    "            nn.GroupNorm(1,out_c)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        if self.residual:\n",
    "            return self.relu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels , out_channels , down_t):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "        nn.MaxPool3d(2),\n",
    "        DoubleConv(in_channels , in_channels, residual=True),\n",
    "        DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "        \n",
    "        self.maxpool_conv_t = nn.Sequential(\n",
    "            nn.MaxPool3d(down_t),\n",
    "            DoubleConv(num_window, out_channels),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x,t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        t = self.maxpool_conv_t(t)\n",
    "        return x + t\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__ (self,in_channels, out_channels, down_t):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels,residual=True),\n",
    "            DoubleConv(in_channels, out_channels,in_channels//2),\n",
    "        )\n",
    "        self.maxpool_conv_t = nn.Sequential(\n",
    "            nn.MaxPool3d(down_t),\n",
    "            DoubleConv(num_window, out_channels),\n",
    "        )\n",
    "    def forward(self,x, skip_x,t):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = torch.cat([skip_x,x],dim=1)\n",
    "        x= self.conv(x)\n",
    "        t = self.maxpool_conv_t(t)\n",
    "        return x + t\n",
    "    \n",
    "\n",
    "class ConvAttentionBlock_2C(nn.Module):\n",
    "    def __init__(self, nf=64, bias=True):\n",
    "        super(ConvAttentionBlock_2C,self).__init__()\n",
    "        self.nf = nf\n",
    "        self.convQ1 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convK1 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convV1 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convQ2 = nn.Conv3d(nf, nf, 3,1,1)\n",
    "        self.convV3 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "#         self.tan = nn.Tanh()\n",
    "        self.instance_norm = nn.InstanceNorm3d(nf)\n",
    "        self.convTurn1 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convTurn2= nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convK2 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convV2 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convQ3 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convK3 = nn.Conv3d(nf, nf, 3,  1,1)\n",
    "        self.convTurn3 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.convTurn = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "         # initialization\n",
    "        default_init_weights([self.convTurn1,self.convTurn2,self.convTurn3,self.convTurn,self.convQ1,self.convK1,self.convV1 ,self.convQ2,self.convK2,self.convV2 ,self.convQ3,self.convK3,self.convV3,self.convTurn], 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        m = x.size(2)\n",
    "        h = x.size(4)\n",
    "        size = m*m*h\n",
    "        Q1 = self.convQ1(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        K1 = self.convK1(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf).permute(0, 2, 1)\n",
    "        V1= self.convV1(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        Q2 = self.convQ2(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        K2 = self.convK2(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf).permute(0, 2, 1)\n",
    "        V2= self.convV2(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        Q3 = self.convQ3(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        K3 = self.convK3(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf).permute(0, 2, 1)\n",
    "        V3= self.convV3(x).permute((0, 2, 3, 4, 1)).view(-1,size,self.nf)\n",
    "        \n",
    "        B1 = (self.convTurn1(torch.bmm( V1 , self.relu((torch.bmm(K1, Q1)/math.sqrt(self.nf)).float()) ).permute(0, 2, 1).view(-1,self.nf,m,m,h)))\n",
    "        B2 = (self.convTurn2(torch.bmm( V2 , self.relu((torch.bmm(K2, Q2)/math.sqrt(self.nf)).float()) ).permute(0, 2, 1).view(-1,self.nf,m,m,h)))\n",
    "        B3 = (self.convTurn3(torch.bmm( V3 , self.relu((torch.bmm(K3, Q3)/math.sqrt(self.nf)).float()) ).permute(0, 2, 1).view(-1,self.nf,m,m,h)))\n",
    "        \n",
    "        x = self.instance_norm(self.convTurn(x + (0.3 * (B1+B2+B3))))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvAttention(nn.Module):\n",
    "    '''Residual in Residual Dense Block'''\n",
    "\n",
    "    def __init__(self, nf):\n",
    "        super(ConvAttention, self).__init__()\n",
    "        self.CAB1 = ConvAttentionBlock_2C(nf)\n",
    "        self.CAB2 = ConvAttentionBlock_2C(nf)\n",
    "        self.conv1 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.conv2 = nn.Conv3d(nf, nf, 3, 1,1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.CAB1(x)\n",
    "        x = self.relu(self.conv1(x + out)) \n",
    "        out = self.CAB2(x)\n",
    "        x = self.relu(self.conv2(x + out)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCUNet(nn.Module):\n",
    "    def __init__(self,c_in=8+4+3,c_out_s=2*num_predict_window,c_out_p = num_predict_window):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inc = DoubleConv(c_in,8)\n",
    "        self.down1 = Down(8,16,2)\n",
    "        self.sa1 = ConvAttention(16)\n",
    "        self.down2 = Down(16,32,4)\n",
    "        self.sa2 = ConvAttention(32)\n",
    "        self.down3 = Down(32,64,8)\n",
    "        self.sa3 = ConvAttention(64)\n",
    "        \n",
    "        self.bot1 = DoubleConv(64,128)\n",
    "        self.bot2 = DoubleConv(128,128)\n",
    "        self.bot3 = DoubleConv(128,64)\n",
    "        \n",
    "        self.up1 = Up(64+32,32,4)\n",
    "        self.sa4 = ConvAttention(32)\n",
    "        self.up2 = Up(32+16,16,2)\n",
    "        self.sa5 = ConvAttention(16)\n",
    "        \n",
    "        self.up3_s = Up(16+8,16,1)\n",
    "        self.up3_p = Up(16+8,8,1)\n",
    "        self.out_s = nn.Conv3d(16,c_out_s,kernel_size=1,stride=1,padding=0)\n",
    "        self.out_p = nn.Conv3d(8,c_out_p,kernel_size=1,stride=1,padding=0)\n",
    "    def forward(self,x,t):\n",
    "        #down sample\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1,t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2,t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3,t)\n",
    "        x4 = self.sa3(x4)\n",
    "        \n",
    "        \n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "        \n",
    "        #up sample\n",
    "        x = self.up1(x4,x3,t)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x,x2,t)\n",
    "        x = self.sa5(x)\n",
    "        x_s = self.up3_s(x,x1,t)\n",
    "        x_p = self.up3_p(x,x1,t)\n",
    "        x_s = self.out_s(x_s)\n",
    "        x_p = self.out_p(x_p)\n",
    "        return torch.cat([x_s,x_p],dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCUNet().to(device2)\n",
    "from torch.nn import DataParallel\n",
    "model = nn.DataParallel(model, device_ids=[]) ##choice gpu id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2 * 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc89982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VDirect(Pressure, K, c):\n",
    "    Pressure.requires_grad_(True)\n",
    "    if c == 1:\n",
    "        mu = 8e-4\n",
    "    if c == 0:\n",
    "        mu = 0.0141\n",
    "    dx = torch.zeros_like(Pressure).to(device2).float()\n",
    "    dx[:, :-1, :, :] = Pressure[:, 1:, :, :] - Pressure[:, :-1, :, :]\n",
    "    \n",
    "    dy = torch.zeros_like(Pressure).to(device2).float()\n",
    "    dy[:, :, :-1, :] = Pressure[:, :, 1:, :] - Pressure[:, :, :-1, :]\n",
    "    \n",
    "    dz = torch.zeros_like(Pressure).to(device2).float()\n",
    "    dz[:, :, :, :-1] = Pressure[:, :, :, 1:] - Pressure[:, :, :, :-1]\n",
    "    \n",
    "    return  (-K * dx/ mu).detach(),  (-K *dy/ mu).detach(), (-K *dz/ mu).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba78057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RErrorS(S_n_plus_one,S_n,Pressure,K,Pore): \n",
    "    S_n_plus_one = S_n_plus_one.reshape(-1,2*num_predict_window,16,16,8)[:,-2:,:,:,:]\n",
    "    S_n = S_n.reshape(-1,2*num_predict_window,16,16,8)[:,-2:,:,:,:]\n",
    "    Pressure = Pressure.reshape(-1,num_predict_window,16,16,8)[:,-1,:,:,:]\n",
    "    K = K.reshape(-1,16,16,8)\n",
    "    Pore = Pore.reshape(-1,16,16,8)\n",
    "\n",
    "    R = torch.zeros_like(S_n_plus_one).to(device2).float()\n",
    "    \n",
    "    for c in range(2):\n",
    "        vx,vy,vz = VDirect(Pressure,K,c)\n",
    "        for i in range(7, 10):\n",
    "            for j in range(7, 10):\n",
    "                for k in range(4, 6):\n",
    "                    time_diff = (S_n_plus_one[:,c,i,j,k] - S_n[:,c,i,j,k]) / 2. #/ dt\n",
    "\n",
    "                    x_diff = vx[:,i+1,j,k] * (S_n[:,c,i+1,j,k] - S_n[:,c,i-1,j,k]) / 2.#(2*dx)\n",
    "                    y_diff = vy[:,i,j+1,k] * (S_n[:,c,i,j+1,k] - S_n[:,c,i,j-1,k]) / 2.#(2*dy)\n",
    "                    z_diff = vz[:,i,j,k+1] * (S_n[:,c,i,j,k+1] - S_n[:,c,i,j,k-1]) / 2.#(2*dz)\n",
    "\n",
    "                    boundary_term = Pore[:,i,j,k]\n",
    "\n",
    "                    R[:,c,i,j,k] = torch.pow((time_diff + x_diff + y_diff + z_diff - boundary_term),2)\n",
    "    return R.sum()/(2*3*3*2*R.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFCUNet(model, train_loader, val_loader, optimizer, p=0.9, num_epochs=1000):\n",
    "    train_losses = []  \n",
    "    train_saturation_losses =[]\n",
    "    train_pressure_losses = []\n",
    "    val_losses = []  \n",
    "    val_saturation_losses =[]\n",
    "    val_pressure_losses = []\n",
    "    train_R_losses = []\n",
    "    val_R_losses = []\n",
    "    num_iters = (num_step-num_window)/num_predict_window\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_saturation_loss = 0.0\n",
    "        train_pressure_loss = 0.0\n",
    "        train_R_loss = 0.0\n",
    "        step = [np.ones((img_n,img_n,img_h)) * i for i in range(num_step-num_predict_window)]\n",
    "        step_emb = torch.from_numpy(np.concatenate(step, axis=0).reshape(num_step-num_predict_window,img_n,img_n,img_h)/ num_step).float()\n",
    "        for batch in train_loader:\n",
    "            targets ,intermidates,Pressure,K,Pore= batch[0].to(device2), batch[1].to(device2),batch[2].to(device2),batch[3].to(device2),batch[4].to(device2)\n",
    "            sequence_saturation = torch.zeros_like(targets)\n",
    "            sequence_pressure = torch.zeros_like(Pressure)\n",
    "            sequence_saturation[:,:,:num_window,:,:,:] = targets[:,:,:num_window,:,:,:]\n",
    "            sequence_pressure[:,:num_window,:,:,:] = Pressure[:,:num_window,:,:,:]\n",
    "            for s in range(int(num_iters)):\n",
    "                optimizer.zero_grad()\n",
    "                begin = s*num_predict_window\n",
    "                t = step_emb[begin:(num_window+begin),:,:,:].reshape(num_window,img_n,img_n,img_h).to(device2).repeat(targets.size(0),1,1,1,1)\n",
    "                tar_saturation = targets[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,2*num_predict_window,img_n,img_n,img_h)\n",
    "                tar_pressure = Pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,num_predict_window,img_n,img_n,img_h)\n",
    "                tar = torch.cat([tar_saturation,tar_pressure],dim=1)\n",
    "                saturation = sequence_saturation[:,:,begin:(num_window+begin),:,:,:].reshape(-1,2*num_window,img_n,img_n,img_h)\n",
    "                pressure = sequence_pressure[:,begin:(num_window+begin),:,:,:].reshape(-1,num_window,img_n,img_n,img_h)\n",
    "                teacher_forcing = True if torch.rand(1) <= p else False\n",
    "                if teacher_forcing or s == 0:\n",
    "                    saturation = targets[:,:,begin:(num_window+begin),:,:,:].reshape(-1,2*num_window,img_n,img_n,img_h)\n",
    "                    pressure = Pressure[:,begin:(num_window+begin),:,:,:].reshape(-1,num_window,img_n,img_n,img_h)\n",
    "                inputs = torch.cat([saturation,pressure,intermidates],dim=1)\n",
    "                outputs = model(inputs, t)\n",
    "                Rloss = 0.1 * RErrorS(outputs[:,:2*num_predict_window,:,:,:],targets[:,:,(num_window+begin-1):(num_predict_window+num_window+begin-1),:,:,:],Pressure[:,(num_window+begin-1):(num_predict_window+num_window+begin-1),:,:,:]*2./1e-7,K,Pore)\n",
    "                step_total_loss = loss_fn(tar,outputs) + Rloss\n",
    "                step_total_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                output_saturation = outputs[:,:2*num_predict_window,:,:,:].detach()\n",
    "                output_pressure = outputs[:,2*num_predict_window:,:,:,:].detach()\n",
    "#               \n",
    "\n",
    "                train_loss += step_total_loss.item()\n",
    "                step_saturation_loss = loss_fn(tar_saturation,output_saturation)\n",
    "                step_pressure_loss = loss_fn(tar_pressure,output_pressure)\n",
    "                train_saturation_loss += step_saturation_loss.item()\n",
    "                train_pressure_loss += step_pressure_loss.item()\n",
    "                train_R_loss += Rloss.item()\n",
    "                sequence_saturation[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_saturation.reshape(-1,2,num_predict_window,img_n,img_n,img_h)\n",
    "                sequence_pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_pressure\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_saturation_loss = 0.0\n",
    "        val_pressure_loss = 0.0\n",
    "        val_R_loss=0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                targets ,intermidates,Pressure,K,Pore= batch[0].to(device2), batch[1].to(device2),batch[2].to(device2),batch[3].to(device2),batch[4].to(device2)\n",
    "                sequence_saturation = torch.zeros_like(targets)\n",
    "                sequence_pressure = torch.zeros_like(Pressure)\n",
    "                sequence_saturation[:,:,:num_window,:,:,:] = targets[:,:,:num_window,:,:,:]\n",
    "                sequence_pressure[:,:num_window,:,:,:] = Pressure[:,:num_window,:,:,:]\n",
    "                for s in range(int(num_iters)):\n",
    "                    begin = s*num_predict_window\n",
    "                    t = step_emb[begin:(num_window+begin),:,:,:].reshape(num_window,img_n,img_n,img_h).to(device2).repeat(targets.size(0),1,1,1,1)\n",
    "                    tar_saturation = targets[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,2*num_predict_window,img_n,img_n,img_h)\n",
    "                    tar_pressure = Pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,num_predict_window,img_n,img_n,img_h)\n",
    "                    tar = torch.cat([tar_saturation,tar_pressure],dim=1)\n",
    "                    saturation = sequence_saturation[:,:,begin:(num_window+begin),:,:,:].reshape(-1,2*num_window,img_n,img_n,img_h)\n",
    "                    pressure = sequence_pressure[:,begin:(num_window+begin),:,:,:].reshape(-1,num_window,img_n,img_n,img_h)\n",
    "                    inputs = torch.cat([saturation,pressure,intermidates],dim=1)\n",
    "                    outputs = model(inputs,t)\n",
    "                    output_saturation = outputs[:,:2*num_predict_window,:,:,:].detach()\n",
    "                    output_pressure = outputs[:,2*num_predict_window:,:,:,:].detach()\n",
    "                    step_saturation_loss = loss_fn(tar_saturation,output_saturation)\n",
    "                    step_pressure_loss = loss_fn(tar_pressure,output_pressure)\n",
    "                    Rloss = 0.1 * RErrorS(outputs[:,:2*num_predict_window,:,:,:],targets[:,:,(num_window+begin-1):(num_predict_window+num_window+begin-1),:,:,:],Pressure[:,(num_window+begin-1):(num_predict_window+num_window+begin-1),:,:,:]*2./1e-7,K,Pore)\n",
    "                    step_total_loss = loss_fn(tar,outputs) + Rloss\n",
    "                    val_loss += step_total_loss.item()\n",
    "                    val_saturation_loss += step_saturation_loss.item()\n",
    "                    val_pressure_loss += step_pressure_loss.item()\n",
    "                    val_R_loss += Rloss.item()\n",
    "                    sequence_saturation[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_saturation.reshape(-1,2,num_predict_window,img_n,img_n,img_h)\n",
    "                    sequence_pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_pressure\n",
    "\n",
    "        train_loss /= (len(train_loader)*num_iters)\n",
    "        train_pressure_loss /= (len(train_loader)*num_iters)\n",
    "        train_saturation_loss /= (len(train_loader)*num_iters)\n",
    "        val_loss /= (len(val_loader)*num_iters)\n",
    "        val_pressure_loss /= (len(val_loader)*num_iters)\n",
    "        val_saturation_loss /= (len(val_loader)*num_iters)\n",
    "        val_R_loss /= (len(val_loader)*num_iters)\n",
    "        train_R_loss /= (len(train_loader)*num_iters)\n",
    "        \n",
    "        train_losses.append(train_loss) \n",
    "        train_pressure_losses.append(train_pressure_loss)\n",
    "        train_saturation_losses.append(train_saturation_loss)\n",
    "        val_losses.append(val_loss)  \n",
    "        val_pressure_losses.append(val_pressure_loss)\n",
    "        val_saturation_losses.append(val_saturation_loss)\n",
    "        val_R_losses.append(val_R_loss)\n",
    "        train_R_losses.append(train_R_loss)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, S: {train_saturation_loss:.4f}, P: {train_pressure_loss:.4f}, R:{train_R_loss:.4f}\"\n",
    "                                            f\" Val Loss: {val_loss:.4f}, S: {val_saturation_loss:.4f}, P: {val_pressure_loss:.4f}, R:{val_R_loss:.4f} \")\n",
    "        if p > 0:\n",
    "            p -= 0.008\n",
    "        if (epoch+1) % 5 == 0 :\n",
    "            torch.save(model.state_dict(),\"../\"%(epoch+1)) #save pth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFCUNet(model, train_loader, valid_loader, optimizer, p=0.9,num_epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
