{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.nn import init as init\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device2 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_step = 20 #five years\n",
    "num_window = 4\n",
    "num_predict_window = 16\n",
    "img_n = 16\n",
    "img_h = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_plus(Dataset):\n",
    "    def __init__(self, label_dir):\n",
    "        self.label_dir = os.path.join(label_dir, \"S\")\n",
    "        self.refine_well_dir = os.path.join(label_dir, \"Well\")\n",
    "        self.K_dir = os.path.join(label_dir, \"K\")\n",
    "        self.Pore_dir = os.path.join(label_dir, \"Pore\")\n",
    "        self.Pressure_dir = os.path.join(label_dir, \"Pressure\")\n",
    "        \n",
    "\n",
    "        self.refine_file_list = os.listdir(self.refine_well_dir)\n",
    "        self.K_file_list = os.listdir(self.K_dir)\n",
    "        self.Pore_file_list = os.listdir(self.Pore_dir)\n",
    "        self.Pressure_file_list = os.listdir(self.Pressure_dir)\n",
    "        \n",
    "        self.label_file_list = os.listdir(self.label_dir )\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_file_list)* 4\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // 4\n",
    "        rotation_index = index % 4\n",
    "        refine_file_name = self.refine_file_list[file_index]\n",
    "        K_file_name = self.K_file_list[file_index]\n",
    "        \n",
    "        Pore_file_name = self.Pore_file_list[file_index]\n",
    "        Pressure_file_name = self.Pressure_file_list[file_index]\n",
    "        \n",
    "        label_file_name = self.label_file_list[file_index]\n",
    "        \n",
    "        refine_file_path = os.path.join(self.refine_well_dir, refine_file_name)\n",
    "        K_file_path = os.path.join(self.K_dir, K_file_name)\n",
    "        Pore_file_path = os.path.join(self.Pore_dir, Pore_file_name)\n",
    "        Pressure_file_path = os.path.join(self.Pressure_dir, Pressure_file_name)\n",
    "        \n",
    "        label_file_path = os.path.join(self.label_dir, label_file_name)\n",
    "        \n",
    "        K_data = scipy.io.loadmat(K_file_path)\n",
    "        K_array = (np.log(K_data['K']))\n",
    "        K_tensor = torch.from_numpy(K_array).reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        \n",
    "        Pore_data = scipy.io.loadmat(Pore_file_path)\n",
    "        Pore_array = Pore_data['p']\n",
    "        Pore_tensor = torch.from_numpy(Pore_array).reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        \n",
    "        Pressure_data = scipy.io.loadmat(Pressure_file_path)\n",
    "        Pressure_array = (Pressure_data['pressure'])\n",
    "        Pressure_tensor = torch.from_numpy(Pressure_array.transpose(3,0,1,2))[:num_step].to(device2).float()* 1e-7  / 2. # (38,16,16,8)\n",
    "        Pressure_tensor = torch.rot90(Pressure_tensor, k=rotation_index, dims=(1, 2))\n",
    "      \n",
    "        label_data = scipy.io.loadmat(label_file_path)\n",
    "        label_array = label_data['Ssmatrix']\n",
    "        \n",
    "        label_refine_well = torch.from_numpy(scipy.io.loadmat(refine_file_path)[\"wc_globale_refine\"]).to(device2).float() #用于loss使用\n",
    "        \n",
    "        input_refine_well = label_refine_well.reshape(1,img_n,img_n,img_h).to(device2).float()\n",
    "        \n",
    "        intermediate_condition = torch.cat([F.normalize(K_tensor,dim=0),F.normalize(Pore_tensor,dim=0),input_refine_well],axis=0)\n",
    "        intermediate_condition = torch.rot90(intermediate_condition, k=rotation_index, dims=(1, 2))\n",
    "        \n",
    "        label_tensor = torch.from_numpy(label_array.transpose(3,4,0,1,2))[:,:num_step].to(device2)\n",
    "        label_tensor = torch.rot90(label_tensor, k=rotation_index, dims=(2, 3))\n",
    "        return  (label_tensor).float(),(intermediate_condition).float(),Pressure_tensor.float()\n",
    "\n",
    "label_dir = '../CO2Datasets/refine/' \n",
    "dataset = CustomDataset_plus(label_dir)\n",
    "\n",
    "# train_size = int(0.9 * len(dataset))\n",
    "# valid_size = len(dataset) - train_size\n",
    "# # print(valid_size)\n",
    "# train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "# torch.save(train_dataset,'./pt/train_dataset.pt')\n",
    "# torch.save(valid_dataset,'./pt/valid_dataset.pt')\n",
    "\n",
    "train_dataset = torch.load('./pt/train_dataset.pt')\n",
    "valid_dataset = torch.load('./pt/valid_dataset.pt')\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_weights(module_list, scale=1, bias_fill=0, **kwargs):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Args:\n",
    "        module_list (list[nn.Module] | nn.Module): Modules to be initialized.\n",
    "        scale (float): Scale initialized weights, especially for residual\n",
    "            blocks. Default: 1.\n",
    "        bias_fill (float): The value to fill bias. Default: 0\n",
    "        kwargs (dict): Other arguments for initialization function.\n",
    "    \"\"\"\n",
    "    if not isinstance(module_list, list):\n",
    "        module_list = [module_list]\n",
    "    for module in module_list:\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, **kwargs)\n",
    "                m.weight.data *= scale\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(bias_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_c,out_c,mid_c=None,residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        \n",
    "        if not mid_c:\n",
    "            mid_c = out_c\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_c,mid_c,kernel_size=3,padding=1),\n",
    "            nn.GroupNorm(1,mid_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_c,out_c,kernel_size=3,padding=1),\n",
    "            nn.GroupNorm(1,out_c)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        if self.residual:\n",
    "            return self.relu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "        nn.MaxPool3d(2),\n",
    "        DoubleConv(in_channels , in_channels, residual=True),\n",
    "        DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.maxpool_conv(x)\n",
    "        return x\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__ (self,in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels,residual=True),\n",
    "            DoubleConv(in_channels, out_channels,in_channels//2),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x, skip_x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = torch.cat([skip_x,x],dim=1)\n",
    "        x= self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,c_in=8+4+3,c_out_s=2*num_predict_window,c_out_p = num_predict_window):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inc = DoubleConv(c_in,8)\n",
    "        self.down1 = Down(8,16)\n",
    "        self.down2 = Down(16,32)\n",
    "        self.down3 = Down(32,64)\n",
    "        \n",
    "        self.bot1 = DoubleConv(64,128)\n",
    "        self.bot2 = DoubleConv(128,128)\n",
    "        self.bot3 = DoubleConv(128,64)\n",
    "        \n",
    "        self.up1 = Up(64+32,32)\n",
    "        self.up2 = Up(32+16,16)\n",
    "        \n",
    "        self.up3_s = Up(16+8,16)\n",
    "        self.up3_p = Up(16+8,8)\n",
    "        \n",
    "        self.out_s = nn.Conv3d(16,c_out_s,kernel_size=1,stride=1,padding=0)\n",
    "        self.out_p = nn.Conv3d(8,c_out_p,kernel_size=1,stride=1,padding=0)\n",
    "    def forward(self,x):\n",
    "        x1 = self.inc(x)\n",
    "#         x1 = self.sa0(x1)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        \n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "        \n",
    "        x = self.up1(x4,x3)\n",
    "        x = self.up2(x,x2)\n",
    "        x_s = self.up3_s(x,x1)\n",
    "        x_p = self.up3_p(x,x1)\n",
    "        x_s = self.out_s(x_s)\n",
    "        x_p = self.out_p(x_p)\n",
    "        return torch.cat([x_s,x_p],dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device2)\n",
    "from torch.nn import DataParallel\n",
    "model = nn.DataParallel(model, device_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2 * 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainUNet(model, train_loader, val_loader, optimizer,  num_epochs=1000):\n",
    "    train_losses = [] \n",
    "    train_saturation_losses =[]\n",
    "    train_pressure_losses = []\n",
    "    val_losses = [] \n",
    "    val_saturation_losses =[]\n",
    "    val_pressure_losses = []\n",
    "    num_iters = (num_step-num_window)/num_predict_window\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_saturation_loss = 0.0\n",
    "        train_pressure_loss = 0.0\n",
    "        step = [np.ones((img_n,img_n,img_h)) * i for i in range(num_step-num_predict_window)]\n",
    "        step_emb = torch.from_numpy(np.concatenate(step, axis=0).reshape(num_step-num_predict_window,img_n,img_n,img_h)/ num_step).float()\n",
    "        for batch in train_loader:\n",
    "            targets ,intermidates,Pressure= batch[0].to(device2), batch[1].to(device2),batch[2].to(device2)\n",
    "            sequence_saturation = torch.zeros_like(targets)\n",
    "            sequence_pressure = torch.zeros_like(Pressure)\n",
    "            sequence_saturation[:,:,:num_window,:,:,:] = targets[:,:,:num_window,:,:,:]\n",
    "            sequence_pressure[:,:num_window,:,:,:] = Pressure[:,:num_window,:,:,:]\n",
    "            for s in range(int(num_iters)):\n",
    "                optimizer.zero_grad()\n",
    "                begin = s*num_predict_window\n",
    "                tar_saturation = targets[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,2*num_predict_window,img_n,img_n,img_h)\n",
    "                tar_pressure = Pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,num_predict_window,img_n,img_n,img_h)\n",
    "                tar = torch.cat([tar_saturation,tar_pressure],dim=1)\n",
    "                saturation = targets[:,:,begin:(num_window+begin),:,:,:].reshape(-1,2*num_window,img_n,img_n,img_h)\n",
    "                pressure = Pressure[:,begin:(num_window+begin),:,:,:].reshape(-1,num_window,img_n,img_n,img_h)\n",
    "                \n",
    "                inputs = torch.cat([saturation,pressure,intermidates],dim=1)\n",
    "                outputs = model(inputs)\n",
    "                step_total_loss = loss_fn(tar,outputs)\n",
    "                step_total_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                output_saturation = outputs[:,:2*num_predict_window,:,:,:].detach()\n",
    "                output_pressure = outputs[:,2*num_predict_window:,:,:,:].detach()\n",
    "#               \n",
    "\n",
    "                train_loss += step_total_loss.item()\n",
    "                step_saturation_loss = loss_fn(tar_saturation,output_saturation)\n",
    "                step_pressure_loss = loss_fn(tar_pressure,output_pressure)\n",
    "                train_saturation_loss += step_saturation_loss.item()\n",
    "                train_pressure_loss += step_pressure_loss.item()\n",
    "                sequence_saturation[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_saturation.reshape(-1,2,num_predict_window,img_n,img_n,img_h)\n",
    "                sequence_pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_pressure\n",
    "  \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_saturation_loss = 0.0\n",
    "        val_pressure_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                targets ,intermidates,Pressure= batch[0].to(device2), batch[1].to(device2),batch[2].to(device2)\n",
    "                sequence_saturation = torch.zeros_like(targets)\n",
    "                sequence_pressure = torch.zeros_like(Pressure)\n",
    "                sequence_saturation[:,:,:num_window,:,:,:] = targets[:,:,:num_window,:,:,:]\n",
    "                sequence_pressure[:,:num_window,:,:,:] = Pressure[:,:num_window,:,:,:]\n",
    "                for s in range(int(num_iters)):\n",
    "                    begin = s*num_predict_window\n",
    "                    \n",
    "                    tar_saturation = targets[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,2*num_predict_window,img_n,img_n,img_h)\n",
    "                    tar_pressure = Pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:].reshape(-1,num_predict_window,img_n,img_n,img_h)\n",
    "                    tar = torch.cat([tar_saturation,tar_pressure],dim=1)\n",
    "                    saturation = sequence_saturation[:,:,begin:(num_window+begin),:,:,:].reshape(-1,2*num_window,img_n,img_n,img_h)\n",
    "                    pressure = sequence_pressure[:,begin:(num_window+begin),:,:,:].reshape(-1,num_window,img_n,img_n,img_h)\n",
    "                    inputs = torch.cat([saturation,pressure,intermidates],dim=1)\n",
    "                    outputs = model(inputs)\n",
    "                    output_saturation = outputs[:,:2*num_predict_window,:,:,:].detach()\n",
    "                    output_pressure = outputs[:,2*num_predict_window:,:,:,:].detach()\n",
    "                    step_saturation_loss = loss_fn(tar_saturation,output_saturation)\n",
    "                    step_pressure_loss = loss_fn(tar_pressure,output_pressure)\n",
    "                    step_total_loss = loss_fn(tar,outputs)\n",
    "                    val_loss += step_total_loss.item()\n",
    "                    val_saturation_loss += step_saturation_loss.item()\n",
    "                    val_pressure_loss += step_pressure_loss.item()\n",
    "                    sequence_saturation[:,:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_saturation.reshape(-1,2,num_predict_window,img_n,img_n,img_h)\n",
    "                    sequence_pressure[:,(num_window+begin):(num_predict_window+num_window+begin),:,:,:] = output_pressure\n",
    "\n",
    "        train_loss /= (len(train_loader)*num_iters)\n",
    "        train_pressure_loss /= (len(train_loader)*num_iters)\n",
    "        train_saturation_loss /= (len(train_loader)*num_iters)\n",
    "        val_loss /= (len(val_loader)*num_iters)\n",
    "        val_pressure_loss /= (len(val_loader)*num_iters)\n",
    "        val_saturation_loss /= (len(val_loader)*num_iters)\n",
    "\n",
    "        train_losses.append(train_loss)  \n",
    "        train_pressure_losses.append(train_pressure_loss)\n",
    "        train_saturation_losses.append(train_saturation_loss)\n",
    "        val_losses.append(val_loss) \n",
    "        val_pressure_losses.append(val_pressure_loss)\n",
    "        val_saturation_losses.append(val_saturation_loss)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, S: {train_saturation_loss:.4f}, P: {train_pressure_loss:.4f},\"\n",
    "                                            f\" Val Loss: {val_loss:.4f}, S: {val_saturation_loss:.4f}, P: {val_pressure_loss:.4f} \")\n",
    "        if (epoch+1) % 5 == 0 :\n",
    "            torch.save(model.state_dict(),\" \"%(epoch+1)) #save pth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUNet(model, train_loader, valid_loader, optimizer,num_epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
